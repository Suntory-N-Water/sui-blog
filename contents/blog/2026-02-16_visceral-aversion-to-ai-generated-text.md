---
title: AIを使い倒す人間が、AI文章に萎える理由
slug: visceral-aversion-to-ai-generated-text
date: 2026-02-16
modified_time: 2026-02-16
description: 24時間365日AIを使い倒している私が、技術記事のAI生成文章に感じる「ゾワッ」の正体を言語化した。Markdown記法の残留、不自然なコロン、型定義のないTypeScript。「またAIね」と萎える瞬間に潜む3つの感情と、使い手だからこその「手抜きの透視能力」、そして不完全性が価値を持つ時代について。
icon: 🫠
icon_url: /icons/melting_face_flat.svg
tags:
  - ポエム
  - AI
---

## 「ゾワッ」とする瞬間

技術記事を読んでいて、突然くる。

Markdownの太字記法 `**` がそのまま残っている。文末に不自然な「:」(コロン)がくっついている。「詳しくはこちら👉」という機械的な誘導フレーズ。TypeScriptで書かれているはずのコード例なのに、型定義がどこにもない。コンパイルすらできない。

「ああ、またAIね」

萎える。瞬時に読む気が失せる。

この感覚、心当たりがある人はどれほどいるでしょうか。

私は生成AIを死ぬほど使っている。24時間365日、起きている間は常に何かしらのAIを動かしている。会社でも一番使っている自信がある。それなのに、技術記事でAI生成文章を見ると「きめえな」と感じてしまう。

矛盾している。自覚はある。

2025年ごろから、生成AIが市民権を得て使う人間が爆発的に増えた。見かける件数が増えたぶん、「ゾワッ」とする回数も増えた。この感覚を言語化しようと思ったきっかけは単純で、技術記事という「ある程度人間が考える必要がある場面」で、明らかに生成AIから貼り付けただけの文言を見たから。

## 嫌悪感の正体

この感覚は何なのか。哲学者と対話する機会があり、「ゾワッ」を分解してみた。結果として、3つの層が見えてきた。

### 不気味の谷

最初にくるのは直感的な違和感。「なんか臭うな」「この文章、どこかで見たことあるな」という感覚。

人間らしく振る舞っているものの中に「異質なもの」を検知した瞬間の、本能的な警戒心。ロボットが人間に似すぎると不気味に感じるあれと同じ現象が、文章でも起きている。

厳密に言えば、AIの文章には間違いが含まれていることもある。でも人間の回答だって間違うことはあるので、そこは許容範囲。問題は、「まるっきり100%違うやん」というレベルのものが混ざっていること。TypeScriptのファイルなのに型定義がないとか、その時点でコンパイルすらできない。動作確認をしていないことが丸わかり。

### 共感性羞恥

次に湧いてくるのは、怒りに近い感情。

共感性羞恥(Vicarious Embarrassment)という概念がある。他者の恥ずかしい行動を見て、自分が恥ずかしくなる現象のこと。AI文章がそのまま貼り付けられているのを見ると、「推敲していない」ことが透けて見えて、いたたまれない気持ちになる。

「推敲もできないなら載せるなよ」と思ってしまう。

一番ムカつくのは、明らかに生成AIで作っているのに「これは私の文章です」という顔をしているケース。「AIで書きました」と最初から宣言してくれるなら、まだマシ。

### 情報汚染への危機感

最後に、もっと根深い懸念が残る。

実際のメディアでSEOを高めるためにAI記事を量産する会社は、いくつも知っている。知らない人からすれば「めちゃくちゃ記事を書いているすごい会社だな」と映るだろう。採用にも効いているのかもしれない。悪意はないのだと思う。

でも、ネットに転がっている情報を元にLLMが推論して出力した文章が、検証もされずに公開されている。その情報を読んだ誰かが、間違った内容をそのまま実装する。これは「手抜き」以前の問題で、情報環境そのものを劣化させている。

間違った情報を垂れ流しにすることへの憤り。この3つ目の層が、嫌悪感の一番深い部分にある。

## 使い手だからこその「透視能力」

「AIを24時間365日使う人間が、AI生成文章に最も嫌悪感を抱いている」

この逆説は偶然じゃない。

料理人が冷凍食品をレンジで温めただけの料理を一瞬で見抜くように、AIを使いこなしているからこそ「推敲していない」ことが分かる。

私自身、ブログの記事を書くときにAIは使う。ただし、あくまで構成の補助として。「こういう内容を書きたいけど、よい感じの言い回しが思いつかない」というとき、提案させて、最終的には自分が実際に話すであろう言葉に変換している。頭で思っていることがそのまま出力されるなら、それは手抜きじゃない。

問題は、頭で思っていることと実際にアウトプットされる言葉が一致していないこと。本人が内容を理解しているかどうかも、文章からは判断できない。そこが気持ち悪い。

もしかしたら、AIを使わない人はこの「AI臭さ」に鈍感なのかもしれない。つまり、この嫌悪感は「AIリテラシーの高さ」の裏返しでもある。

## 不完全性が価値を持つ時代

ここでおもしろい発見がある。

AIは誤字脱字を絶対にしない。確率で言葉を出しているのだから、当たり前。だからタイポや誤字脱字を見ると、逆に「まだこっちの方が人間味があってよいよね」と感じる。

昔は「恥ずべきミス」だったタイポが、AI時代では「人間の証明」になりつつある。

数年前の自分のブログを読み返すと、正直、読めたものではない。2022年ごろの記事は文章が稚拙で読みづらい。でも、そこには成長の跡がある。「味」がある。最初から全部ガチガチの生成AI文章よりも、よっぽどよい。

完璧すぎる文章は不自然さを生む。不完全であることが価値になる時代が来ている。

## 人間の役割は「尖ること」と「検証すること」

AI文章は「それっぽいこと」を確率的に出力する。安全制御で全方位配慮をたたき込まれているから、「Aだ」と言い切ることを避けて、「Aという説もありますが、Bという側面もあります」という毒にも薬にもならない文章になりがち。

だから人間がやるべきことは2つある。

1つは、「本当にそうなのか?」を検証すること。私自身、ここ1年で意識的に変えたことがある。公式ドキュメントから内容を引用するなら、必ず一次情報にあたって「ここにこう書いてある」と明記する。コードの実装だけでなく、「ドキュメントにこう書いてあるからこうした」という意図まで書くようになった。エビデンスの徹底。AI時代だからこそ、一次情報の価値が際立つ。

もう1つは、「尖り散らかしたこと」を書くこと。AI文章にはそれができない。個人の技術記事に求めるのは、ただの情報じゃない。思想。世相。その人の価値観が載った文章。

中世ヨーロッパの絵画は、写真が登場する前は「いかに精密に描くか」が最も重要だった。写真が出てからは抽象画や日常風景にシフトした。文章でも同じことが起きるんじゃないか。AIが「正確な情報の出力」を担当するなら、人間は「尖った思想と一次体験」を担当すればよい。

## 守りたいもの

結局、私が見たいのは「人間臭いもの」。

整いすぎたAI文章より、不完全でも人間味のある文章の方が読者の心に届く。主観を入れてほしい。スタンスを取ってほしい。話が行ったり来たりしたってよい。多少矛盾していてもよい。あってもなくてもよい雑談が入っていてもよい。そういう文章に、書き手の思考過程や感情の動きが滲む。

「AI文章かどうかなんて気にしない」という人もいるだろう。内容の良し悪しだけを見ているのかもしれない。それなら、AIに直接聞けばよくないですか。わざわざ記事を読む意味は、そこに人間の思考があるから。私はそう思う。

この感覚を「潔癖症だ」と言う人がいたら、全然潔癖症でかまわない。あくまで私の思想であって、押し付けるつもりはない。ただ、「こういった価値観はどうですか?」と問いかけたいだけ。

5年後、この「AI臭さ」は消えているかもしれない。プロンプトをいじるだけで文体は変わるし、学習データも改善される。でも、推敲しないという姿勢が変わらなければ、別の形で「手抜き」は透けて見えるだろう。私は別の基準で見抜くようになるだけ。

私はAIを否定しない。道具として最大限に活用し続ける。ただ、冷凍食品をレンジで温めただけのものを「手作りです」とは言わない。

もしあなたが記事を書いているなら、一度見直してみてほしい。推敲してください。それだけで、あなたの文章は劇的に良くなる。

## まとめ

- AI文章への嫌悪感には、「不気味の谷」「共感性羞恥」「情報汚染への危機感」という3つの層がある
- AIを使い倒す人間ほど「推敲していない」ことを見抜ける。使い手だからこその透視能力
- タイポに親近感を覚える時代がきた。AIは誤字脱字を絶対にしないから、不完全性が人間の証明になりつつある
- AI時代の人間の役割は「検証すること」と「尖ること」。エビデンスと一次体験の価値がますます高まる
- AI文章そのものが悪いのではなく、推敲せずに出すことが問題。推敲してください。それだけのこと
